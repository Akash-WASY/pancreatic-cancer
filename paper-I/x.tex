% Generated by GrindEQ Word-to-LaTeX 
\documentclass{article} % use \documentstyle for old LaTeX compilers

\usepackage[english]{babel} % 'french', 'german', 'spanish', 'danish', etc.
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{txfonts}
\usepackage{mathdots}
\usepackage[classicReIm]{kpfonts}
\usepackage{graphicx}

% You can include more LaTeX packages here 


\begin{document}

%\selectlanguage{english} % remove comment delimiter ('%') and select language if required


\noindent 

\noindent 

\noindent 

\noindent 

\noindent \textbf{Data distribution}

\noindent \textbf{}

\noindent Prior to starting the model fitting process, save the time variable in \textit{T} and the event/status variable in \textit{E}.

\noindent To gain a general sense of the distribution, let's plot a histogram of the time variable. According to the histogram, the time variable almost exhibits a Weibull or Log-normal distribution. During the phase of AFT model estimation, we shall verify that.

\noindent \textbf{}

\noindent \includegraphics*[width=6.57in, height=4.33in, keepaspectratio=false]{image1}\textbf{}

\noindent \textbf{}

\noindent \textbf{}

\noindent \textbf{}

\noindent \textbf{Estimation of the Kaplan-Maier Curve (Non-Parametric)}

\noindent \textbf{}

\noindent First, we have a collection of patient deaths events. While we watch some patients, others might be rightly censored. In other words, we know that they existed up until a certain point but are unsure of what transpired later. In clinical trials, censoring could occur as a result of participants dropping out or the study coming to an end. Frequently, we just have one straightforward variable, if not none at all, with which to stratify our patients. Estimating the survival function is something we're interested in.

\noindent \textbf{}

\noindent \textbf{}

\noindent \textbf{}

\noindent \textbf{}

\noindent \textbf{}

\noindent \textbf{}

\noindent \textbf{}

\noindent \textbf{Adaptive Lasso estimator}  is the solution of


\[\underbrace{\mathrm{min}}_{\beta }\left\{-\frac{\mathrm{1}}{n}l_n\left(\beta \right)+\lambda \sum^d_{j\mathrm{=1}}{}\left|{\beta }_j\right|{\tau }_j\right\}\mathrm{\ }\mathrm{(1)}\] 
where the positive weights $\tau \mathrm{=(}{\tau }_{\mathrm{1}},{\tau }_{\mathrm{2}},....,{\tau }_d{\mathrm{)}}^T$ are determined based on data in an adaptive manner. For the solution to be optimal, the values selected for the ${\tau }_j$'s are essential. Utilizing ${\tau }_j\mathrm{=1/}\left|{\widetilde{\beta }}_j\right|$ (where $\widetilde{\beta }$ = $\mathrm{(}{\beta }_{\mathrm{1}},...,{\beta }_d{\mathrm{)}}^T$ is the maximizer of the log partial likelihood $l_n\mathrm{(}\beta \mathrm{)}$) is our suggestion. As consistent estimators, their values accurately reflect the relative weights of the covariates (\textit{Tsiatis, 1981; Andersen   Gill, 1982}). Therefore, we concentrate on the issue. 

\noindent 
\[\underbrace{\mathrm{min}}_{\beta }\left\{-\frac{\mathrm{1}}{n}l_n\left(\beta \right)+\lambda \sum^d_{j\mathrm{=1}}{}\left|{\beta }_j\right|\mathrm{/}\left|{\widetilde{\beta }}_j\right|\right\}\mathrm{(2)}\] 
Any reliable estimates of $\beta $ may be utilised; $\widetilde{\beta }$ is merely a practical option. In the wavelet literature (\textit{Donoho Johnstone, 1998; Antoniadis Fan, 2001}), the $L_0$ penalty $\sum^d_{j\mathrm{=1}}{}I\mathrm{(}{\widetilde{\beta }}_j\rlap{/}\mathrm{=}\mathrm{0)}$ also known as the \textbf{entropy penalty}, is closely connected to the adaptive penalty factor in equation \eqref{GrindEQ__2_}. The term $\left|{\beta }_j\right|\mathrm{/}\left|{\widetilde{\beta }}_j\right|$ converges to $I\mathrm{(}{\widetilde{\beta }}_j\mathrm{\neq }\mathrm{0)}$with probability as $n\to \infty $ because of the consistency of ${\widetilde{\beta }}_j$. As a result, in an asymptotic sense, the adaptive Lasso technique can be seen as an automatic implementation of best-subset selection.




\end{document}

